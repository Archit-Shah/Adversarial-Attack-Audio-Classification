{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download Dataset\n",
    "\n",
    "Download the Urban8K dataset from the link below:\n",
    "\n",
    "https://urbansounddataset.weebly.com/download-urbansound8k.html\n",
    "\n",
    "The page will ask for basic details and then direct to the download link. The data size is about 6GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Unzip the Dataset\n",
    "\n",
    "Once downloaded, unzip the file in \"..\\data\\unzipped\\\" folder path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import librosa\n",
    "from librosa import display\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pylab\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from shutil import copy\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Spectrogram Folder\n",
    "\n",
    "Create a folder to store spectrogram images for various puposes.\n",
    "\n",
    "1. Create folder path \"..\\spectogram_images\\train\"\n",
    "2. Create folder path \"..\\spectogram_images\\test\"\n",
    "3. Create folder path \"..\\spectogram_images\\adv_train_in\"\n",
    "4. Create folder path \"..\\spectogram_images\\adv_test_in\"\n",
    "5. Create folder path \"..\\spectogram_images\\adv_train_out\"\n",
    "6. Create folder path \"..\\spectogram_images\\adv_test_out\"\n",
    "7. Create folder path \"..\\spectrogram_images\\train_adv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('spectrogram_images/train'):\n",
    "    os.makedirs('spectrogram_images/train')\n",
    "if not os.path.exists('spectrogram_images/test'):\n",
    "    os.makedirs('spectrogram_images/test')\n",
    "if not os.path.exists('spectrogram_images/adv_train_in'):\n",
    "    os.makedirs('spectrogram_images/adv_train_in')\n",
    "if not os.path.exists('spectrogram_images/adv_test_in'):\n",
    "    os.makedirs('spectrogram_images/adv_test_in')\n",
    "if not os.path.exists('spectrogram_images/adv_test_out'):\n",
    "    os.makedirs('spectrogram_images/adv_test_out')\n",
    "if not os.path.exists('spectrogram_images/adv_train_out'):\n",
    "    os.makedirs('spectrogram_images/adv_train_out')\n",
    "if not os.path.exists('spectrogram_images/train_adv'):\n",
    "    os.makedirs('spectrogram_images/train_adv')\n",
    "if not os.path.exists('adv_train_models/'):\n",
    "    os.makedirs('adv_train_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Files in Batch to generate and save Spectogram images\n",
    "ADV_MODELS_DIR = \"adv_train_models/\"\n",
    "WAV_DIR = 'data/unzipped/UrbanSound8K/audio/fold'\n",
    "IMG_DIR = 'spectrogram_images/train/'\n",
    "I_ADV_TRAIN_DIR = 'spectrogram_images/adv_train_in/'\n",
    "I_ADV_TEST_DIR = 'spectrogram_images/adv_test_in/'\n",
    "O_ADV_TRAIN_DIR = 'spectrogram_images/adv_train_out/'\n",
    "O_ADV_TEST_DIR = 'spectrogram_images/adv_test_out/'\n",
    "\n",
    "ADV_TRAIN_DIR = 'spectrogram_images/train_adv/'\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(1,4):\n",
    "for i in range(1,9):\n",
    "    wav_files = os.listdir(WAV_DIR + str(i) + '/')\n",
    "    for f in wav_files:\n",
    "        try:\n",
    "            # Read wav-file\n",
    "            y, sr = librosa.load(WAV_DIR + str(i) + '/' + f, sr = 22050)\n",
    "\n",
    "            # Compute spectrogram\n",
    "            M = librosa.feature.melspectrogram(y, sr, fmax = sr/2, n_fft=2048, hop_length=512, n_mels = 96, power = 2)\n",
    "\n",
    "            # Power in DB\n",
    "            log_power = librosa.power_to_db(M, ref=np.max)\n",
    "\n",
    "            # Plotting the spectrogram\n",
    "            pylab.figure(figsize=(5,5))\n",
    "            pylab.axis('off') \n",
    "            pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "            librosa.display.specshow(log_power, cmap=cm.jet)\n",
    "            pylab.savefig(IMG_DIR + f[:-4]+'.jpg', bbox_inches=None, pad_inches=0)\n",
    "            pylab.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f, e)\n",
    "            pass\n",
    "\n",
    "for i in range(9,10):\n",
    "    wav_files = os.listdir(WAV_DIR + str(i) + '/')\n",
    "    for f in wav_files:\n",
    "        try:\n",
    "            # Read wav-file\n",
    "            y, sr = librosa.load(WAV_DIR + str(i) + '/' + f, sr = 22050)\n",
    "\n",
    "            # Compute spectrogram\n",
    "            M = librosa.feature.melspectrogram(y, sr, fmax = sr/2, n_fft=2048, hop_length=512, n_mels = 96, power = 2)\n",
    "\n",
    "            # Power in DB\n",
    "            log_power = librosa.power_to_db(M, ref=np.max)\n",
    "\n",
    "            # Plotting the spectrogram\n",
    "            pylab.figure(figsize=(5,5))\n",
    "            pylab.axis('off') \n",
    "            pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "            librosa.display.specshow(log_power, cmap=cm.jet)\n",
    "            pylab.savefig(I_ADV_TRAIN_DIR + f[:-4]+'.jpg', bbox_inches=None, pad_inches=0)\n",
    "            pylab.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f, e)\n",
    "            pass\n",
    "        \n",
    "for i in range(10,11):\n",
    "    wav_files = os.listdir(WAV_DIR + str(i) + '/')\n",
    "    for f in wav_files:\n",
    "        try:\n",
    "            # Read wav-file\n",
    "            y, sr = librosa.load(WAV_DIR + str(i) + '/' + f, sr = 22050)\n",
    "\n",
    "            # Compute spectrogram\n",
    "            M = librosa.feature.melspectrogram(y, sr, fmax = sr/2, n_fft=2048, hop_length=512, n_mels = 96, power = 2)\n",
    "\n",
    "            # Power in DB\n",
    "            log_power = librosa.power_to_db(M, ref=np.max)\n",
    "\n",
    "            # Plotting the spectrogram\n",
    "            pylab.figure(figsize=(5,5))\n",
    "            pylab.axis('off') \n",
    "            pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "            librosa.display.specshow(log_power, cmap=cm.jet)\n",
    "            pylab.savefig(I_ADV_TEST_DIR + f[:-4]+'.jpg', bbox_inches=None, pad_inches=0)\n",
    "            pylab.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f, e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = 'spectrogram_images/train/'\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 16\n",
    "BATCH_SIZE = 10\n",
    "L2_LAMBDA = 0.001\n",
    "IMG_SIZE = (224, 224)\n",
    "WAV_DIR = 'data/unzipped/UrbanSound8K/audio/fold'\n",
    "IMG_DIR = 'spectrogram_images/train/'\n",
    "I_ADV_TRAIN_DIR = 'spectrogram_images/adv_train_in/'\n",
    "I_ADV_TEST_DIR = 'spectrogram_images/adv_test_in/'\n",
    "O_ADV_TRAIN_DIR = 'spectrogram_images/adv_train_out/'\n",
    "O_ADV_TEST_DIR = 'spectrogram_images/adv_test_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHotEncoder(categories=[range(NUM_CLASSES)])\n",
    "\n",
    "all_files = os.listdir(IMG_DIR)\n",
    "\n",
    "# Get class weights\n",
    "label_array = []\n",
    "for file_ in all_files:\n",
    "    vals = file_.split('-')[1]\n",
    "    label_array.append(int(vals))\n",
    "    \n",
    "cl_weight = compute_class_weight(class_weight = 'balanced', \n",
    "                                 classes = np.unique(label_array), \n",
    "                                 y = label_array)\n",
    "\n",
    "# Train-val-test split of files\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_files, \n",
    "                                                                      label_array,\n",
    "                                                                      random_state = 10, \n",
    "                                                                      test_size = 0.2\n",
    "                                                                     )\n",
    "\n",
    "# Among the test files, keep half for validation\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(test_files, test_labels,\n",
    "                                                                  random_state = 10, \n",
    "                                                                  test_size = 0.5\n",
    "                                                                 )\n",
    "\n",
    "adv_train_files = os.listdir(I_ADV_TRAIN_DIR)\n",
    "\n",
    "# Get class weights\n",
    "adv_train_label = []\n",
    "for file_ in all_files:\n",
    "    vals = file_.split('-')[1]\n",
    "    adv_train_label.append(int(vals))\n",
    "\n",
    "adv_test_files = os.listdir(I_ADV_TEST_DIR)\n",
    "\n",
    "# Get class weights\n",
    "adv_test_label = []\n",
    "for file_ in all_files:\n",
    "    vals = file_.split('-')[1]\n",
    "    adv_test_label.append(int(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([transforms.Resize(IMG_SIZE), transforms.ToTensor()])\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns tensor\"\"\"\n",
    "    image = Image.open(image_name)\n",
    "    image = image.convert(\"RGB\")\n",
    "    image = loader(image).float()\n",
    "    image = normalize(image).float()\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_batch(file_list):\n",
    "    img_array = []\n",
    "    idx_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for file_ in file_list:\n",
    "        im = IMG_DIR + file_\n",
    "        \n",
    "        img_array.append(np.array(image_loader(im)))\n",
    "\n",
    "        vals = file_.split('-')\n",
    "        idx_array.append(vals[0])\n",
    "        label_array.append([int(vals[1])])\n",
    "\n",
    "    label_array = one_hot.fit_transform(label_array).toarray()\n",
    "    img_array = torch.FloatTensor(img_array)\n",
    "    label_array = torch.LongTensor(label_array)\n",
    "    \n",
    "    return img_array, label_array\n",
    "\n",
    "def batch_generator(files, BATCH_SIZE):\n",
    "    L = len(files)\n",
    "\n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = BATCH_SIZE\n",
    "\n",
    "        while batch_start < L:\n",
    "            \n",
    "            limit = min(batch_end, L)\n",
    "            file_list = files[batch_start: limit]\n",
    "            batch_img_array, batch_label_array = load_batch(file_list)\n",
    "\n",
    "            yield (batch_img_array, batch_label_array) # a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += BATCH_SIZE   \n",
    "            batch_end += BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3)\n",
      "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Model Architecture Definition\n",
    "\n",
    "model = models.vgg16(pretrained=True) #load vgg model\n",
    "\n",
    "# you need to flatten the layer after vgg16 to get 18432, check the keras model in the original nb\n",
    "model.classifier = nn.Sequential(nn.Linear(512*7*7,512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(512,NUM_CLASSES))  \n",
    "# note there is no softmax layer while training, validating and testing put in that operation manually as the learning\n",
    "# doesn't depend upon softmax layer, this way we will get logits. We can use logits in fgsm\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Validation Functions\n",
    "\n",
    "def train (model, loader, criterion):\n",
    "    #Custom Code for Progress Bar\n",
    "    bar = progressbar.ProgressBar(maxval=100, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    model.train()\n",
    "    current_loss = 0\n",
    "    current_correct = 0\n",
    "    i = 0\n",
    "    i_percentage = 0\n",
    "    for train, y_train in iter(loader):\n",
    "        i = i+train.shape[0]\n",
    "        if i > len(train_files):\n",
    "            break\n",
    "        y_train = torch.argmax(y_train, dim=1)\n",
    "        train, y_train = train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(train)\n",
    "        _, preds = torch.max(output,1)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), 50)\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()*train.size(0)\n",
    "        current_correct += torch.sum(preds == y_train.data)\n",
    "        i_percentage = (i/len(train_files))*100\n",
    "        bar.update(i_percentage)\n",
    "        \n",
    "    bar.finish()\n",
    "    epoch_loss = current_loss / len(train_files)\n",
    "    epoch_acc = current_correct.double() / len(train_files)\n",
    "        \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "#validate the model\n",
    "def validation (model, loader, criterion):\n",
    "    #Custom Code for Progress Bar\n",
    "    bar = progressbar.ProgressBar(maxval=100, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_correct = 0\n",
    "    i = 0\n",
    "    i_percentage = 0\n",
    "    for valid, y_valid in iter(loader):\n",
    "        i = i+valid.shape[0]\n",
    "        if i > len(val_files):\n",
    "            break\n",
    "        y_valid = torch.argmax(y_valid, dim=1)\n",
    "        valid, y_valid = valid.to(device), y_valid.to(device)\n",
    "        output = model.forward(valid)\n",
    "        valid_loss += criterion(output, y_valid).item()*valid.size(0)\n",
    "        equal = (output.max(dim=1)[1] == y_valid.data)\n",
    "        valid_correct += torch.sum(equal)#type(torch.FloatTensor)\n",
    "        i_percentage = (i/len(val_files))*100\n",
    "        bar.update(i_percentage)\n",
    "        \n",
    "    bar.finish()\n",
    "    epoch_loss = valid_loss / len(val_files)\n",
    "    epoch_acc = valid_correct.double() / len(val_files)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def testing (model, loader, criterion, test_size):\n",
    "    #Custom Code for Progress Bar\n",
    "    bar = progressbar.ProgressBar(maxval=100, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    i = 0\n",
    "    i_percentage = 0\n",
    "    for test, y_test in iter(loader):\n",
    "        i = i+test.shape[0]\n",
    "        if i > len(test_files):\n",
    "            break\n",
    "        y_test = torch.argmax(y_test, dim=1)\n",
    "        test, y_test = test.to(device), y_test.to(device)\n",
    "        output = model.forward(test)\n",
    "        test_loss += criterion(output, y_test).item()*test.size(0)\n",
    "        equal = (output.max(dim=1)[1] == y_test.data)\n",
    "        test_correct += torch.sum(equal)#type(torch.FloatTensor)\n",
    "        i_percentage = (i/test_size)*100\n",
    "        bar.update(i_percentage)\n",
    "        \n",
    "    bar.finish()\n",
    "    epoch_loss = test_loss / test_size\n",
    "    epoch_acc = test_correct.double() / test_size\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr = 0.005, momentum = 0.5)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 2.0604  Train Accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 1.7759  Validation Accuracy 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Loss : 1.4270  Train Accuracy: 0.5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Validation Loss : 1.4098  Validation Accuracy 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Loss : 1.0505  Train Accuracy: 0.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Validation Loss : 1.1245  Validation Accuracy 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss : 0.7603  Train Accuracy: 0.8281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Validation Loss : 0.9095  Validation Accuracy 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss : 0.5827  Train Accuracy: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Validation Loss : 0.7422  Validation Accuracy 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Train Loss : 0.3931  Train Accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Validation Loss : 0.6035  Validation Accuracy 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Train Loss : 0.3029  Train Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Validation Loss : 0.4662  Validation Accuracy 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Train Loss : 0.2170  Train Accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Validation Loss : 0.3768  Validation Accuracy 1.0000\n",
      "-1033.4592099480033\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Train the model\n",
    "\n",
    "#freeze gradient parameters in pretrained model\n",
    "for param in model.parameters():\n",
    "    param.require_grad = True    \n",
    "\n",
    "#freeze gradient parameters in pretrained model\n",
    "for param in model.features.parameters():\n",
    "    param.require_grad = False\n",
    "    \n",
    "#train and validate\n",
    "#6 epochs seem to be enough\n",
    "epochs = 8\n",
    "epoch = 0\n",
    "\n",
    "start = time.clock()    \n",
    "for e in range(epochs):\n",
    "    epoch +=1\n",
    "    with torch.set_grad_enabled(True):\n",
    "        epoch_train_loss, epoch_train_acc = train(model,batch_generator(train_files,BATCH_SIZE),criteria)\n",
    "    print(\"Epoch: {} Train Loss : {:.4f}  Train Accuracy: {:.4f}\".format(epoch,epoch_train_loss,epoch_train_acc))\n",
    "    with torch.no_grad():\n",
    "        epoch_val_loss, epoch_val_acc = validation(model,batch_generator(val_files,BATCH_SIZE),criteria)\n",
    "    print(\"Epoch: {} Validation Loss : {:.4f}  Validation Accuracy {:.4f}\".format(epoch,epoch_val_loss,epoch_val_acc))\n",
    "print(start - time.clock())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the original training model\n",
    "torch.save(model,'original_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('original_model.pt',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Test Loss : 0.4773  Test Accuracy 0.8750\n"
     ]
    }
   ],
   "source": [
    "#Test Results\n",
    "\n",
    "with torch.no_grad():\n",
    "    epoch_test_loss, epoch_test_acc = testing(model,batch_generator(test_files,BATCH_SIZE),criteria,len(test_files))\n",
    "print(\"Epoch: {} Test Loss : {:.4f}  Test Accuracy {:.4f}\".format(1,epoch_test_loss,epoch_test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  10.00 %\n",
      "-30.6001398563385\n"
     ]
    }
   ],
   "source": [
    "def load_batch_2(file_list):\n",
    "    img_array = []\n",
    "    idx_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for file_ in file_list:\n",
    "        im = I_ADV_TRAIN_DIR + file_\n",
    "        \n",
    "        img_array.append(np.array(image_loader(im)))\n",
    "\n",
    "        vals = file_.split('-')\n",
    "        idx_array.append(vals[0])\n",
    "        label_array.append([int(vals[1])])\n",
    "\n",
    "    label_array = one_hot.fit_transform(label_array).toarray()\n",
    "    img_array = torch.FloatTensor(img_array)\n",
    "    label_array = torch.LongTensor(label_array)\n",
    "    \n",
    "    return img_array, label_array\n",
    "\n",
    "\n",
    "#Generate Adversarial Images\n",
    "batch_size = 5\n",
    "pred = []\n",
    "adv_pred = []\n",
    "if 'adv_x' in locals():\n",
    "    del adv_x\n",
    "\n",
    "i=0\n",
    "bar = progressbar.ProgressBar(maxval=100, \\\n",
    "widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "device = 'cpu'\n",
    "un_normalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],std=[1/0.229, 1/0.224, 1/0.225])\n",
    "un_convert = transforms.ToPILImage()\n",
    "\n",
    "# ADV_IMG_DIR = 'spectrogram_images/adv/'\n",
    "\n",
    "start = time.time()\n",
    "adv_size = len(adv_train_files)\n",
    "file_idx = 0\n",
    "while i<adv_size:\n",
    "    j = i + batch_size\n",
    "    if j>adv_size:\n",
    "        j = adv_size\n",
    "    x,y = load_batch_2(adv_train_files[i:j])\n",
    "    x = Variable(x, requires_grad=True)\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    model = model.to(device)\n",
    "    output = model.forward(x)\n",
    "    y_label = torch.argmax(y, dim=1)\n",
    "    y_label = y_label.to(device)\n",
    "    loss = criteria(output, y_label)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add perturbation \n",
    "    epsilon = 0.01\n",
    "    x_grad     = torch.sign(x.grad.data)\n",
    "    temp = x.data + epsilon*x_grad\n",
    "    if 'adv_x' in locals():\n",
    "        adv_x = torch.cat((adv_x,temp),0)\n",
    "    else:\n",
    "        adv_x = temp\n",
    "    adv_x = adv_x.to(device)\n",
    "    adv_output = model.forward(adv_x)\n",
    "    adv_output = adv_output.to(device)\n",
    "\n",
    "    x_pred = torch.argmax(y, dim=1)\n",
    "    x_adv_pred = torch.argmax(adv_output,dim=1)\n",
    "    \n",
    "    x_pred, x_adv_pred = x_pred.to(device), x_adv_pred.to(device)\n",
    "\n",
    "    pred.extend(x_pred.tolist())\n",
    "    adv_pred.extend(x_adv_pred.tolist())\n",
    "    for ii in range(j-i):\n",
    "        temp = adv_x[ii]\n",
    "        t1 = un_normalize(temp).float()\n",
    "        t2 = un_convert(t1)\n",
    "        t2.save(O_ADV_TRAIN_DIR + adv_train_files[file_idx], \"JPEG\", quality=80, optimize=True, progressive=True)\n",
    "        file_idx += 1\n",
    "        del temp\n",
    "        del t1\n",
    "        del t2\n",
    "    i = j\n",
    "    del adv_x\n",
    "    bar.update((i/adv_size)*100)\n",
    "\n",
    "bar.finish()\n",
    "\n",
    "comp = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == adv_pred[i]:\n",
    "        comp.extend([1])\n",
    "    else:\n",
    "        comp.extend([0])\n",
    "\n",
    "adv_acc = (sum(comp)/len(comp))*100\n",
    "print(\"The accuracy of model with adversarial examples is \",\"{0:.2f}\".format(adv_acc),\"%\")\n",
    "print(start - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the files from training and adversarial images folder into a single training folder\n",
    "import shutil\n",
    "ADV_TRAIN_DIR = 'spectrogram_images/train_adv/'\n",
    "\n",
    "for f in train_files:\n",
    "    shutil.copy2(IMG_DIR + f,ADV_TRAIN_DIR)\n",
    "\n",
    "for f in adv_train_files:\n",
    "    shutil.copy2(O_ADV_TRAIN_DIR + f,ADV_TRAIN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the network now with original + adversarial images\n",
    "adv_files = os.listdir(ADV_TRAIN_DIR)\n",
    "\n",
    "# Get class weights\n",
    "adv_label = []\n",
    "for file_ in adv_files:\n",
    "    vals = file_.split('-')[1]\n",
    "    adv_label.append(int(vals))\n",
    "    \n",
    "cl_weight = compute_class_weight(class_weight = 'balanced', \n",
    "                                 classes = np.unique(label_array), \n",
    "                                 y = label_array)\n",
    "\n",
    "# Train-val-test split of files\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(adv_files, \n",
    "                                                                      adv_label,\n",
    "                                                                      random_state = 10, \n",
    "                                                                      test_size = 0.2\n",
    "                                                                     )\n",
    "\n",
    "# Among the test files, keep half for validation\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(test_files, test_labels,\n",
    "                                                                  random_state = 10, \n",
    "                                                                  test_size = 0.5\n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_train (model, loader, criterion,alpha):\n",
    "    #Custom Code for Progress Bar\n",
    "    bar = progressbar.ProgressBar(maxval=100, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    model.train()\n",
    "    current_loss = 0\n",
    "    current_correct = 0\n",
    "    i = 0\n",
    "    i_percentage = 0\n",
    "    for train, y_train in iter(loader):\n",
    "        train, y_train = train.to(device), y_train.to(device)\n",
    "        train = Variable(train, requires_grad=True)\n",
    "        i = i+train.shape[0]\n",
    "        if i > len(train_files):\n",
    "            break\n",
    "        y_train = torch.argmax(y_train, dim=1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(train)\n",
    "        _, preds = torch.max(output,1)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "#         #adversarial\n",
    "        \n",
    "#         output = model.forward(x)\n",
    "#         y_label = torch.argmax(y, dim=1)\n",
    "#         loss = criteria(output, y_label)\n",
    "#         loss.backward()\n",
    "\n",
    "        # Add perturbation \n",
    "        epsilon = 0.01\n",
    "        train_grad = torch.sign(train.grad.data)\n",
    "        adv_train = train.data + epsilon*train_grad\n",
    "        adv_train = adv_train.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        adv_output = model.forward(adv_train)\n",
    "        adv_output = adv_output.to(device)\n",
    "        _, preds = torch.max(adv_output,1)\n",
    "#       loss = 0.88 * (loss) + 0.12 * (criterion(adv_output, y_train))\n",
    "        loss = alpha * (loss) + (1-alpha) * (criterion(adv_output, y_train))\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.classifier.parameters(), 50)\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()*train.size(0)\n",
    "        current_correct += torch.sum(preds == y_train.data)\n",
    "        i_percentage = (i/len(train_files))*100\n",
    "        bar.update(i_percentage)\n",
    "        \n",
    "    bar.finish()\n",
    "    epoch_loss = current_loss / len(train_files)\n",
    "    epoch_acc = current_correct.double() / len(train_files)\n",
    "        \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Model Architecture Definition\n",
    "\n",
    "model = models.vgg16(pretrained=True) #load vgg model\n",
    "\n",
    "# you need to flatten the layer after vgg16 to get 18432, check the keras model in the original nb\n",
    "model.classifier = nn.Sequential(nn.Linear(512*7*7,512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(512,NUM_CLASSES))  \n",
    "\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr = 0.005, momentum = 0.5)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "#freeze gradient parameters in pretrained model\n",
    "for param in model.parameters():\n",
    "    param.require_grad = True    \n",
    "\n",
    "#freeze gradient parameters in pretrained model\n",
    "for param in model.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch_v(file_list):\n",
    "    img_array = []\n",
    "    idx_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for file_ in file_list:\n",
    "        im = ADV_TRAIN_DIR + file_\n",
    "        \n",
    "        img_array.append(np.array(image_loader(im)))\n",
    "\n",
    "        vals = file_.split('-')\n",
    "        idx_array.append(vals[0])\n",
    "        label_array.append([int(vals[1])])\n",
    "\n",
    "    label_array = one_hot.fit_transform(label_array).toarray()\n",
    "    img_array = torch.FloatTensor(img_array)\n",
    "    label_array = torch.LongTensor(label_array)\n",
    "    \n",
    "    return img_array.to(device), label_array.to(device)\n",
    "\n",
    "def batch_generator_v(files, BATCH_SIZE):\n",
    "    L = len(files)\n",
    "   \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = BATCH_SIZE\n",
    "\n",
    "        while batch_start < L:\n",
    "            \n",
    "            limit = min(batch_end, L)\n",
    "            file_list = files[batch_start: limit]\n",
    "            batch_img_array, batch_label_array = load_batch_v(file_list)\n",
    "\n",
    "            yield (batch_img_array, batch_label_array) # a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += BATCH_SIZE   \n",
    "            batch_end += BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For alpha value:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0670  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0559  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0580  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0531  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0432  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0508  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0631  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0474  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0306  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0438  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0406  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0426  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0312  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0406  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0288  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0393  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0315  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0380  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0252  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0371  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0271  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0359  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0258  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0342  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0175  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0333  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0142  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0324  Validation Accuracy 1.0000\n",
      "\n",
      "For alpha value:  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss : 0.0133  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Validation Loss : 0.0319  Validation Accuracy 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss : 0.0144  Train Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss : 0.0312  Validation Accuracy 1.0000\n",
      "767.6522016525269\n"
     ]
    }
   ],
   "source": [
    "#train and validate\n",
    "#Need to see at what epoch gain stops\n",
    "epochs = 20\n",
    "epoch = 0\n",
    "alpha_values = [0.4,0.5,0.55,0.6,0.65,0.7,0.75,0.8]\n",
    "start = time.time()\n",
    "for alpha in alpha_values:\n",
    "    print(\"\\nFor alpha value: \",alpha)\n",
    "    filepath = \"adv_train_models/adv_model_\"+str(alpha)+\".pt\"\n",
    "    for e in range(epochs):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            epoch_train_loss, epoch_train_acc = adv_train(model,batch_generator_v(train_files,BATCH_SIZE),criteria,alpha)\n",
    "        print(\"Epoch: {} Train Loss : {:.4f}  Train Accuracy: {:.4f}\".format(e,epoch_train_loss,epoch_train_acc))\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss, epoch_val_acc = validation(model,batch_generator_v(val_files,BATCH_SIZE),criteria)\n",
    "        print(\"Epoch: {} Validation Loss : {:.4f}  Validation Accuracy {:.4f}\".format(e,epoch_val_loss,epoch_val_acc))\n",
    "    torch.save(model,filepath)\n",
    "print(time.time() - start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adv = torch.load('adv_train_models/adv_model_0.75.pt',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Test Loss : 4.0330  Test Accuracy 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Test Results\n",
    "\n",
    "with torch.no_grad():\n",
    "    epoch_test_loss, epoch_test_acc = testing(model_adv,batch_generator_v(test_files,BATCH_SIZE),criteria,len(test_files))\n",
    "print(\"Epoch: {} Test Loss : {:.4f}  Test Accuracy {:.4f}\".format(1,epoch_test_loss,epoch_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch_3(file_list):\n",
    "    img_array = []\n",
    "    idx_array = []\n",
    "    label_array = []\n",
    "\n",
    "    for file_ in file_list:\n",
    "        im = I_ADV_TEST_DIR + file_\n",
    "        \n",
    "        img_array.append(np.array(image_loader(im)))\n",
    "\n",
    "        vals = file_.split('-')\n",
    "        idx_array.append(vals[0])\n",
    "        label_array.append([int(vals[1])])\n",
    "\n",
    "    label_array = one_hot.fit_transform(label_array).toarray()\n",
    "    img_array = torch.FloatTensor(img_array)\n",
    "    label_array = torch.LongTensor(label_array)\n",
    "    \n",
    "    return img_array.to(device), label_array.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_attack(model):\n",
    "\n",
    "    start = time.time()\n",
    "    #Generate Adversarial Images\n",
    "    batch_size = 5\n",
    "    pred = []\n",
    "    adv_pred = []\n",
    "    if 'adv_x' in locals():\n",
    "        del adv_x\n",
    "    \n",
    "    i=0\n",
    "    bar = progressbar.ProgressBar(maxval=100, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    un_normalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],std=[1/0.229, 1/0.224, 1/0.225])\n",
    "    un_convert = transforms.ToPILImage()\n",
    "    \n",
    "    # ADV_IMG_DIR = 'spectrogram_images/adv/'\n",
    "    \n",
    "    \n",
    "    adv_size = len(adv_test_files)\n",
    "    file_idx = 0\n",
    "    while i<adv_size:\n",
    "        j = i + batch_size\n",
    "        if j>adv_size:\n",
    "            j = adv_size\n",
    "        x,y = load_batch_3(adv_test_files[i:j])\n",
    "        x = Variable(x, requires_grad=True)\n",
    "        model = model.to(device)\n",
    "        output = model.forward(x)\n",
    "        y_label = torch.argmax(y, dim=1)\n",
    "        loss = criteria(output, y_label)\n",
    "        loss.backward()\n",
    "    \n",
    "        # Add perturbation \n",
    "        epsilon = 0.01\n",
    "        x_grad     = torch.sign(x.grad.data)\n",
    "        temp = x.data + epsilon*x_grad\n",
    "        if 'adv_x' in locals():\n",
    "            adv_x = torch.cat((adv_x,temp),0)\n",
    "        else:\n",
    "            adv_x = temp\n",
    "        adv_x = adv_x.to(device)\n",
    "        adv_output = model.forward(adv_x)\n",
    "    \n",
    "        x_pred = torch.argmax(y, dim=1)\n",
    "        x_adv_pred = torch.argmax(adv_output,dim=1)\n",
    "        \n",
    "    \n",
    "        pred.extend(x_pred.tolist())\n",
    "        adv_pred.extend(x_adv_pred.tolist())\n",
    "        for ii in range(j-i):\n",
    "            temp = adv_x[ii]\n",
    "            temp = temp.to('cpu')\n",
    "            t1 = un_normalize(temp).float()\n",
    "            t2 = un_convert(t1)\n",
    "            t2.save(O_ADV_TEST_DIR + adv_test_files[file_idx], \"JPEG\", quality=80, optimize=True, progressive=True)\n",
    "            file_idx += 1\n",
    "            del temp\n",
    "            del t1\n",
    "            del t2\n",
    "        i = j\n",
    "        del adv_x\n",
    "        bar.update((i/adv_size)*100)\n",
    "    \n",
    "    bar.finish()\n",
    "    \n",
    "    comp = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == adv_pred[i]:\n",
    "            comp.extend([1])\n",
    "        else:\n",
    "            comp.extend([0])\n",
    "    \n",
    "    adv_acc = (sum(comp)/len(comp))*100\n",
    "    print(\"The accuracy of model with adversarial examples is \",\"{0:.2f}\".format(adv_acc),\"%\")\n",
    "    print(\"Elapsed Time: \",time.time() - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Name:  adv_model_0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  27.836429834365845\n",
      "\n",
      "Model Name:  adv_model_0.5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  34.341858863830566\n",
      "\n",
      "Model Name:  adv_model_0.55.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  31.50721001625061\n",
      "\n",
      "Model Name:  adv_model_0.6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  33.811309576034546\n",
      "\n",
      "Model Name:  adv_model_0.65.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  36.622485637664795\n",
      "\n",
      "Model Name:  adv_model_0.7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  33.48609662055969\n",
      "\n",
      "Model Name:  adv_model_0.75.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  32.577117919921875\n",
      "\n",
      "Model Name:  adv_model_0.8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model with adversarial examples is  0.00 %\n",
      "Elapsed Time:  32.06612849235535\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(ADV_MODELS_DIR):\n",
    "    print(\"\\nModel Name: \",f)\n",
    "    m = torch.load(ADV_MODELS_DIR+f,map_location='cpu')\n",
    "    adv_attack(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
